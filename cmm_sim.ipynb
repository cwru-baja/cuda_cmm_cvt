{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math, hashlib, os.path"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## System Consts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "mu = 0.1\n",
    "delta = 1e-3\n",
    "cToC = 0.3\n",
    "L = 1.0\n",
    "sigma = 0.1\n",
    "beta_naught = math.pi / 180.0 * 23 / 2\n",
    "\n",
    "config_string = \"{}-{}-{}-{}-{}-{}\".format(mu, delta, cToC, L, sigma, beta_naught)\n",
    "config_hash = hashlib.sha1(bytes(config_string, 'ascii')).hexdigest()\n",
    "\n",
    "config_root = \"./config/\""
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Gen"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cuda_cmm as cuda_cmm\n",
    "import numpy as np\n",
    "\n",
    "if (not os.path.exists(\"{}cmm_bauxite-{}.npy\".format(config_root, config_hash))):\n",
    "    num_alphas = 2<<6\n",
    "\n",
    "\n",
    "    print(\"\\nBauxite Data Generation\")\n",
    "    # 2.3578\n",
    "    # 3.9254 \n",
    "    alphas = np.linspace(0.7*np.pi, 1/0.7*np.pi, num_alphas, dtype=np.float32)\n",
    "\n",
    "    num_combos = num_alphas\n",
    "    print(\"num_combos:\", num_combos)\n",
    "\n",
    "\n",
    "    vec = np.zeros((num_combos, 4), dtype=np.float32)\n",
    "\n",
    "    # print(\"Starting Vector loading\")\n",
    "    ind = 0\n",
    "    for k in range(num_alphas):\n",
    "        ind = k\n",
    "        vec[ind, 0:3] = [1e9, -1e6, alphas[k]]\n",
    "\n",
    "    print(\"Starting Cuda\")\n",
    "    cuda_cmm.fr(vec, beta_naught, mu)\n",
    "\n",
    "    print(\"\\nCuda Done\")\n",
    "\n",
    "    np.save(\"{}cmm_bauxite-{}.npy\".format(config_root, config_hash), vec)\n",
    "\n",
    "if (not os.path.exists(\"{}cmm_wolframite-{}.npy\".format(config_root, config_hash))):\n",
    "    print(\"\\nWolframite Data Generation\")\n",
    "\n",
    "    num_frs = 2<<9\n",
    "    num_alphas = 2<<9\n",
    "\n",
    "    frs = np.linspace(-1.1, 1.1, num_frs, dtype=np.float32)\n",
    "    alphas = np.linspace(0.7*np.pi, 1/0.7*np.pi, num_alphas, dtype=np.float32)\n",
    "\n",
    "    num_combos = num_frs*num_alphas\n",
    "    print(\"num_combos:\", num_combos)\n",
    "\n",
    "\n",
    "    vec = np.zeros((num_combos, 3), dtype=np.float32)\n",
    "\n",
    "    # print(\"Starting Vector loading\")\n",
    "    ind = 0\n",
    "    for i, fr in enumerate(frs):\n",
    "        for j, alpha in enumerate(alphas):\n",
    "                ind = i * num_alphas + j\n",
    "                vec[ind, 0:2] = [fr, alpha]\n",
    "\n",
    "    print(\"Starting Cuda\")\n",
    "    cuda_cmm.eq_clamp(vec, beta_naught, mu, delta)\n",
    "    print(\"\\nCuda Done\")\n",
    "\n",
    "    np.save(\"{}cmm_wolframite-{}.npy\".format(config_root, config_hash), vec)\n",
    "\n",
    "if (not os.path.exists(\"{}cmm_magnetite-{}.npy\".format(config_root, config_hash))):\n",
    "    print(\"\\nMagnetite Data Generation\")\n",
    "    # float fr = vec[5 * i + 0];\n",
    "    # float A = vec[5 * i + 1];\n",
    "    # float tau = vec[5 * i + 2];\n",
    "\n",
    "    num_frs = 2<<6\n",
    "    num_As = 2<<8\n",
    "    num_taus = 2<<6\n",
    "\n",
    "    frs = np.linspace(-1.1, 1.1, num_frs, dtype=np.float32)\n",
    "    As = np.linspace(-50, 50, num_As, dtype=np.float32)\n",
    "    taus = np.linspace(0.5, 2.0, num_taus, dtype=np.float32)\n",
    "\n",
    "    num_combos = num_frs*num_As*num_taus\n",
    "    print(\"num_combos:\", num_combos)\n",
    "\n",
    "\n",
    "    vec = np.zeros((num_combos, 6), dtype=np.float32)\n",
    "\n",
    "    # print(\"Starting Vector loading\")\n",
    "\n",
    "    for i, fr in enumerate(frs):\n",
    "        for j, A in enumerate(As):\n",
    "            for k, tau in enumerate(taus):\n",
    "                ind = i * num_As * num_taus + j * num_taus  + k\n",
    "                vec[ind, 0:3] = [fr, A, tau]\n",
    "\n",
    "    print(\"Starting Cuda\")\n",
    "    cuda_cmm.c_coefficient(vec, beta_naught, mu, delta, cToC, L, sigma)\n",
    "    # float beta_naught, float mu, float delta, float cToC, float L, float sigma\n",
    "\n",
    "    print(\"\\nCuda Done\")\n",
    "\n",
    "    np.save(\"{}cmm_magnetite-{}.npy\".format(config_root, config_hash), vec)\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Network Definition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "HIDDEN = 512\n",
    "\n",
    "network_config_string = \"{}-{}-{}-{}-{}-{}-{}\".format(mu, delta, cToC, L, sigma, beta_naught, HIDDEN)\n",
    "network_config_hash = hashlib.sha1(bytes(network_config_string, 'ascii')).hexdigest()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using cuda device\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "# Get cpu or gpu device for training.\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "print(f\"Using {device} device\")\n",
    "\n",
    "# Define model\n",
    "class BauxiteNetwork(torch.nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.stack = torch.nn.Sequential(\n",
    "            torch.nn.Linear(1, HIDDEN),\n",
    "            torch.nn.LeakyReLU(),\n",
    "            torch.nn.Linear(HIDDEN, HIDDEN),\n",
    "            torch.nn.LeakyReLU(),\n",
    "            torch.nn.Linear(HIDDEN, HIDDEN),\n",
    "            torch.nn.LeakyReLU(),\n",
    "            torch.nn.Linear(HIDDEN, 1),\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        logits = self.stack(x)\n",
    "        return logits\n",
    "\n",
    "# Define model\n",
    "class WolframiteNetwork(torch.nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.stack = torch.nn.Sequential(\n",
    "            torch.nn.Linear(2, HIDDEN),\n",
    "            torch.nn.LeakyReLU(),\n",
    "            torch.nn.Linear(HIDDEN, HIDDEN),\n",
    "            torch.nn.LeakyReLU(),\n",
    "            torch.nn.Linear(HIDDEN, HIDDEN),\n",
    "            torch.nn.LeakyReLU(),\n",
    "            torch.nn.Linear(HIDDEN, 1),\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        logits = self.stack(x)\n",
    "        return logits\n",
    "\n",
    "# Define model\n",
    "class MagnetiteNetwork(torch.nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.stack = torch.nn.Sequential(\n",
    "            torch.nn.Linear(3, HIDDEN),\n",
    "            torch.nn.LeakyReLU(),\n",
    "            torch.nn.Linear(HIDDEN, HIDDEN),\n",
    "            torch.nn.LeakyReLU(),\n",
    "            torch.nn.Linear(HIDDEN, HIDDEN),\n",
    "            torch.nn.LeakyReLU(),\n",
    "            torch.nn.Linear(HIDDEN, 3),\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        logits = self.stack(x)\n",
    "        return logits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import Dataset\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "class BauxiteDataset(Dataset):\n",
    "    def __init__(self, data_file, transform=None, target_transform=None):\n",
    "        raw_data = np.load(data_file) # [vel, A, alpha, fr]\n",
    "\n",
    "        self.data = torch.tensor(raw_data[np.isfinite(raw_data[:, 2]) & np.isfinite(raw_data[:, 3]), 2:4], dtype=torch.float) # [alpha, fr]\n",
    "\n",
    "        print(raw_data.shape[0] - self.data.shape[0], 'samples removed due to NaNs')\n",
    "\n",
    "        # print(self.data[~torch.isfinite(self.data).all(1)])\n",
    "\n",
    "        self.transform = transform\n",
    "        self.target_transform = target_transform\n",
    "    \n",
    "    def __len__(self):\n",
    "        return self.data.shape[0]\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        state = self.data[idx, 0:1] # [alpha]\n",
    "        label = self.data[idx, 1:2] # [fr]\n",
    "        if self.transform:\n",
    "            state = self.transform(state)\n",
    "        if self.target_transform:\n",
    "            label = self.target_transform(label)\n",
    "        return state, label\n",
    "\n",
    "class WolframiteDataset(Dataset):\n",
    "    def __init__(self, data_file, transform=None, target_transform=None):\n",
    "        raw_data = np.load(data_file) # [fr, alpha, eq_clamp]\n",
    "\n",
    "        self.data = torch.tensor(raw_data[np.isfinite(raw_data[:, 2])], dtype=torch.float) # [fr, alpha, eq_clamp]\n",
    "\n",
    "        print(raw_data.shape[0] - self.data.shape[0], 'samples removed due to NaNs')\n",
    "\n",
    "        # print(self.data[~torch.isfinite(self.data).all(1)])\n",
    "\n",
    "        self.transform = transform\n",
    "        self.target_transform = target_transform\n",
    "    \n",
    "    def __len__(self):\n",
    "        return self.data.shape[0]\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        state = self.data[idx, 0:2] # [fr, alpha]\n",
    "        label = self.data[idx, 2:] # [eq_clamp]\n",
    "        if self.transform:\n",
    "            state = self.transform(state)\n",
    "        if self.target_transform:\n",
    "            label = self.target_transform(label)\n",
    "        return state, label\n",
    "\n",
    "class MagnetiteDataset(Dataset):\n",
    "    def __init__(self, data_file, transform=None, target_transform=None):\n",
    "        raw_data = np.load(data_file) # [fr, A, tau, clamp_ratio, tau_effec, dim_clamp_prim]\n",
    "\n",
    "        clean_data = raw_data[np.isfinite(raw_data[:, 4])]\n",
    "\n",
    "        self.data = torch.tensor(np.c_[clean_data[:, 0], clean_data[:, 2], clean_data[:, 3], clean_data[:, 1], clean_data[:, 4], clean_data[:, 5]], dtype=torch.float) # [fr, tau, clamp_ratio, A, tau_effec, dim_clamp_prim]\n",
    "\n",
    "\n",
    "        print(raw_data.shape[0] - self.data.shape[0], 'samples removed due to NaNs')\n",
    "\n",
    "        self.transform = transform\n",
    "        self.target_transform = target_transform\n",
    "    \n",
    "    def __len__(self):\n",
    "        return self.data.shape[0]\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        state = self.data[idx, 0:3] # [fr, tau, clamp_ratio]\n",
    "        label = self.data[idx, 3:] # [A, tau_effec, Q]\n",
    "        if self.transform:\n",
    "            state = self.transform(state)\n",
    "        if self.target_transform:\n",
    "            label = self.target_transform(label)\n",
    "        return state, label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 samples removed due to NaNs\n",
      "0 samples removed due to NaNs\n",
      "0 samples removed due to NaNs\n"
     ]
    }
   ],
   "source": [
    "BATCH_SIZE = 2048\n",
    "\n",
    "def train(dataloader, model, loss_fn, optimizer):\n",
    "            size = len(dataloader.dataset)\n",
    "            model.train()\n",
    "            for batch, (X, y) in enumerate(dataloader):\n",
    "                X, y = X.to(device).float(), y.to(device).float()\n",
    "\n",
    "                # Compute prediction error\n",
    "                pred = model(X)\n",
    "                loss = loss_fn(pred, y)\n",
    "\n",
    "                # Backpropagation\n",
    "                optimizer.zero_grad()\n",
    "                loss.backward()\n",
    "                optimizer.step()\n",
    "\n",
    "def test(dataloader, model, loss_fn, check_fn):\n",
    "    # size = len(dataloader.dataset)\n",
    "    num_batches = len(dataloader)\n",
    "    model.eval()\n",
    "    test_loss = 0\n",
    "    check_val = 0\n",
    "    with torch.no_grad():\n",
    "        for X, y in dataloader:\n",
    "            X, y = X.to(device).float(), y.to(device).float()\n",
    "            pred = model(X)\n",
    "\n",
    "            test_loss += loss_fn(pred, y).item()\n",
    "            check_val += check_fn(pred, y).item()\n",
    "    test_loss /= num_batches\n",
    "    check_val /= num_batches\n",
    "\n",
    "    return test_loss, check_val\n",
    "\n",
    "\n",
    "for model, name, dataset in [(BauxiteNetwork(), \"bauxite\", BauxiteDataset(\"{}cmm_bauxite-{}.npy\".format(config_root, config_hash))), (WolframiteNetwork(), \"wolframite\", WolframiteDataset(\"{}cmm_wolframite-{}.npy\".format(config_root, config_hash))), (MagnetiteNetwork(), \"magnetite\", MagnetiteDataset(\"{}cmm_magnetite-{}.npy\".format(config_root, config_hash)))]:\n",
    "    if (not os.path.exists(\"{}cmm_{}-{}.pth\".format(config_root, name, network_config_hash))):\n",
    "        print(\"Training {} network\".format(name))\n",
    "        model = model.to(device)\n",
    "\n",
    "        loss_fn = torch.nn.MSELoss()\n",
    "        check_fn = torch.nn.L1Loss()\n",
    "\n",
    "        lr = 0.9e-6\n",
    "        optimizer = torch.optim.RMSprop(model.parameters(), lr=lr)\n",
    "        import time\n",
    "\n",
    "        cmm_dataloader = DataLoader(dataset, batch_size=BATCH_SIZE, shuffle=True)\n",
    "        last_loss = 30.0\n",
    "\n",
    "        epochs = 50\n",
    "        epochs = 10\n",
    "        for t in range(epochs):\n",
    "            start = time.perf_counter()\n",
    "            if t % 10 == 0:\n",
    "                lr /= 8\n",
    "                optimizer = torch.optim.RMSprop(model.parameters(), lr=lr)\n",
    "                # print(\"\\nlr = \", lr)\n",
    "\n",
    "\n",
    "            train(cmm_dataloader, model, loss_fn, optimizer)\n",
    "            test_loss, check_val = test(cmm_dataloader, model, loss_fn, check_fn)\n",
    "            print(f\"Epoch {t+1}\", (f\"Old loss: {last_loss:>8f} New loss: {test_loss:>8f} Check fn: {check_val:>8f}\"), \"Took {:.3f}\".format(time.perf_counter() - start), end=\"\\r\")\n",
    "\n",
    "            last_loss = test_loss\n",
    "\n",
    "        print(\"Done!\")\n",
    "        torch.save(model.state_dict(), \"{}cmm_{}-{}.pth\".format(config_root, name, network_config_hash))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BauxiteNetwork(\n",
      "  (stack): Sequential(\n",
      "    (0): Linear(in_features=1, out_features=512, bias=True)\n",
      "    (1): LeakyReLU(negative_slope=0.01)\n",
      "    (2): Linear(in_features=512, out_features=512, bias=True)\n",
      "    (3): LeakyReLU(negative_slope=0.01)\n",
      "    (4): Linear(in_features=512, out_features=512, bias=True)\n",
      "    (5): LeakyReLU(negative_slope=0.01)\n",
      "    (6): Linear(in_features=512, out_features=1, bias=True)\n",
      "  )\n",
      ")\n",
      "WolframiteNetwork(\n",
      "  (stack): Sequential(\n",
      "    (0): Linear(in_features=2, out_features=512, bias=True)\n",
      "    (1): LeakyReLU(negative_slope=0.01)\n",
      "    (2): Linear(in_features=512, out_features=512, bias=True)\n",
      "    (3): LeakyReLU(negative_slope=0.01)\n",
      "    (4): Linear(in_features=512, out_features=512, bias=True)\n",
      "    (5): LeakyReLU(negative_slope=0.01)\n",
      "    (6): Linear(in_features=512, out_features=1, bias=True)\n",
      "  )\n",
      ")\n",
      "MagnetiteNetwork(\n",
      "  (stack): Sequential(\n",
      "    (0): Linear(in_features=3, out_features=512, bias=True)\n",
      "    (1): LeakyReLU(negative_slope=0.01)\n",
      "    (2): Linear(in_features=512, out_features=512, bias=True)\n",
      "    (3): LeakyReLU(negative_slope=0.01)\n",
      "    (4): Linear(in_features=512, out_features=512, bias=True)\n",
      "    (5): LeakyReLU(negative_slope=0.01)\n",
      "    (6): Linear(in_features=512, out_features=3, bias=True)\n",
      "  )\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "bauxite = BauxiteNetwork()\n",
    "bauxite.load_state_dict(torch.load(\"{}cmm_bauxite-{}.pth\".format(config_root, network_config_hash)))\n",
    "bauxite.to(device).eval()\n",
    "\n",
    "wolframite = WolframiteNetwork()\n",
    "wolframite.load_state_dict(torch.load(\"{}cmm_wolframite-{}.pth\".format(config_root, network_config_hash)))\n",
    "wolframite.to(device).eval()\n",
    "\n",
    "magnetite = MagnetiteNetwork()\n",
    "magnetite.load_state_dict(torch.load(\"{}cmm_magnetite-{}.pth\".format(config_root, network_config_hash)))\n",
    "magnetite.to(device).eval()\n",
    "\n",
    "print(bauxite)\n",
    "print(wolframite)\n",
    "print(magnetite)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Engine Loading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: numpy in c:\\users\\willm\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (1.23.1)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip available: 22.3 -> 22.3.1\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    }
   ],
   "source": [
    "%pip install numpy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "209.43951023931956 18.642525 18.642525\n",
      "230.3834612632515 18.710316000000002 18.710316000000002\n",
      "251.32741228718345 18.913688999999998 18.913688999999998\n",
      "272.2713633111154 18.98148 18.98148\n",
      "293.21531433504737 18.913688999999998 18.913688999999998\n",
      "314.1592653589793 18.845898000000002 18.845898000000002\n",
      "335.1032163829113 18.642525 18.642525\n",
      "356.0471674068432 18.303569999999997 18.30357\n",
      "376.99111843077515 17.62566 17.62566\n"
     ]
    }
   ],
   "source": [
    "import csv\n",
    "import numpy as np\n",
    "\n",
    "ENGINE = \"BRIGGS\"\n",
    "# ENGINE = \"KHOLER\"\n",
    "\n",
    "filename = \"\"\n",
    "if ENGINE == \"BRIGGS\":\n",
    "    filename = \"BriggsModel19Data.csv\"\n",
    "elif ENGINE == \"KHOLER\":\n",
    "    filename = \"RestrictedKohlerCH440.csv\"\n",
    "\n",
    "data = []\n",
    "\n",
    "with open(filename, newline='') as csvfile:\n",
    "    spamreader = csv.reader(csvfile, delimiter=',', quotechar='|')\n",
    "    spamreader.__next__() # Skip header\n",
    "    for row in spamreader:\n",
    "        rpm = int(row[0])\n",
    "\n",
    "        omega = rpm / 60 * 2 * np.pi # rpm to rad/s\n",
    "        power = float(row[1]) * 745.7 # hp to W\n",
    "        torque = float(row[2]) * 1.35582 # Lb-Ft to N-m\n",
    "\n",
    "        data.append((omega, power, torque))\n",
    "\n",
    "data_ray = np.array(data)\n",
    "pow_ray = data_ray[:, [0, 1]]\n",
    "tor_ray = data_ray[:, [0, 2]]\n",
    "\n",
    "# max_speed = data_ray[-1][0]\n",
    "\n",
    "def ndd(ray):\n",
    "    if ray.shape[0] == 2:\n",
    "        return (ray[1][1] - ray[0][1]) / (ray[1][0] - ray[0][0])\n",
    "    else:\n",
    "        return (ndd(ray[1:]) - ndd(ray[:-1])) / (ray[-1][0] - ray[0][0])\n",
    "\n",
    "\n",
    "# test_ray = np.asarray([[0.0, 10], [1.0, 20], [2.0, 10]])\n",
    "# test_ray\n",
    "# compute nddp of torque\n",
    "tor_coeffs = np.zeros((data_ray.shape[0]))\n",
    "\n",
    "\n",
    "tor_coeffs[0] = tor_ray[0][1]\n",
    "for i in range(1, data_ray.shape[0]):\n",
    "    tor_coeffs[i] = ndd(tor_ray[0: i + 1])\n",
    "\n",
    "# print(tor_coeffs)\n",
    "\n",
    "def tor_nddp(omega):\n",
    "    y = tor_coeffs[0] * omega ** 0\n",
    "    \n",
    "    prod = omega ** 0\n",
    "    for i in range(1, tor_coeffs.shape[0]):\n",
    "        prod *= omega - tor_ray[i - 1][0]\n",
    "        y += tor_coeffs[i] * prod\n",
    "    \n",
    "    return y\n",
    "\n",
    "# Check the NDDP at all the points\n",
    "for omega, torque in tor_ray:\n",
    "    print(omega, tor_nddp(omega), torque)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "397.9351 10.914327939019799\n"
     ]
    }
   ],
   "source": [
    "print(397.9351, tor_nddp(397.9351))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Run the Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def rand_range(lower, upper, rand):\n",
    "    return lower + (upper - lower) * rand"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "16\n",
      "Iter: 600 t[-1] 0.100 x[-1] 0.00000 omega[-1] 398.15335 R_p[-1] 0.10000 R_s[-1] 0.23368 Natural Tension: 2511.61914\t\t\t\t\r"
     ]
    }
   ],
   "source": [
    "SIMS = 16384 // 1024\n",
    "print(SIMS)\n",
    "# SIMS = 1\n",
    "ITERS = 600\n",
    "\n",
    "NEWTON_STEPS = 100\n",
    "NEWTON_THRESH = 1e-6\n",
    "\n",
    "with torch.no_grad():\n",
    "\n",
    "    def solveForOther(radius, cToC, L):\n",
    "            def L_prime(other_radius):\n",
    "                theta_t = torch.asin((other_radius - radius) / cToC)\n",
    "\n",
    "                alpha_radius = torch.pi - 2 * theta_t\n",
    "                alpha_other_radius = torch.pi + 2 * theta_t\n",
    "                length = radius * alpha_radius + other_radius * alpha_other_radius + 2 * torch.sqrt(cToC**2 - (other_radius - radius)**2)\n",
    "\n",
    "                return length\n",
    "\n",
    "            def dL_dOther(other_radius):\n",
    "                theta_t = torch.asin((other_radius - radius) / cToC)\n",
    "                alpha_other_radius = torch.pi + 2 * theta_t\n",
    "\n",
    "                dthetaT = 1 / torch.sqrt(1 - (other_radius - radius) / cToC) * (1 / cToC)\n",
    "\n",
    "                dalpha_other = 2 * dthetaT\n",
    "\n",
    "                dsl_dOther = 0.5 * (cToC**2 - (other_radius - radius)**2)**(-0.5) * (-2 * (other_radius - radius))\n",
    "\n",
    "                delta_length = alpha_other_radius + other_radius * dalpha_other + 2 * dsl_dOther\n",
    "\n",
    "                return delta_length\n",
    "\n",
    "            # Newtons Method to find Radii that fit the speed ratio and belt length\n",
    "            guess = radius.clone()\n",
    "            iter = 0\n",
    "            discrep = torch.ones(SIMS, 1, device=device, requires_grad=False)\n",
    "            while (torch.abs(discrep) > NEWTON_THRESH).any() and iter < NEWTON_STEPS:\n",
    "                discrep = L_prime(guess) - L\n",
    "                # print(\"Iter:\", iter, \"guess:\", guess, \"discrep:\", discrep, \"slope:\", dL_dOther(guess))\n",
    "                guess -= discrep / dL_dOther(guess)\n",
    "\n",
    "                iter += 1\n",
    "\n",
    "            return guess\n",
    "\n",
    "    def dLdRp(r_p, r_s, cToC):\n",
    "        return torch.pi - 2 * torch.atan((r_s - r_p)/cToC) - 2/cToC * (r_s - r_p) / (1 + ((r_s - r_p)/cToC)**2) - 2 * r_p / (cToC**2 + (r_s - r_p)**2).sqrt()\n",
    "\n",
    "    def dLdRs(r_p, r_s, cToC):\n",
    "        return torch.pi + 2 * torch.atan((r_s - r_p)/cToC) + 2/cToC * (r_s - r_p) / (1 + ((r_s - r_p)/cToC)**2) + 2 * r_s / (cToC**2 + (r_s - r_p)**2).sqrt()\n",
    "    \n",
    "    DELTA_T = 0.001 * torch.ones(SIMS, 1, device=device)\n",
    "\n",
    "\n",
    "    beta_naught = math.pi / 180.0 * 23 / 2\n",
    "    mu = 0.1\n",
    "    sheave_terms = (1 + math.cos(beta_naught)**2) / math.sin(2 * beta_naught)\n",
    "    delta = 1e-3\n",
    "\n",
    "    # Engine Config\n",
    "    omega = 2000/60*2*math.pi * torch.ones(SIMS, 1, device=device, requires_grad=False)\n",
    "    throttle = 1.0\n",
    "    engine_inertia = 0.1 * 0.5 # kg * m^2\n",
    "\n",
    "    # CVT Config\n",
    "    cToC = 0.350\n",
    "    L = 1.8\n",
    "    sigma = 0.1 # kg / m\n",
    "    natural_tension = torch.zeros(SIMS, 1, device=device, requires_grad=False)\n",
    "\n",
    "    r_p = torch.ones(SIMS, 1, device=device, requires_grad=False) * 0.1\n",
    "\n",
    "    r_s = solveForOther(r_p, cToC, L)\n",
    "\n",
    "    tau_time = np.zeros((ITERS, 2))\n",
    "\n",
    "    # Clamp Config\n",
    "    o_gain = rand_range(0.0, 2.0, torch.rand(SIMS, 1, device=device)) # N * sec / rad\n",
    "    rad_gain = rand_range(0.0, 2.0, torch.rand(SIMS, 1, device=device)) # N\n",
    "\n",
    "    rad_gain_s = rand_range(0.0, 2.0, torch.rand(SIMS, 1, device=device)) # N\n",
    "    torque_gain_s = rand_range(-2.0, 0.0, torch.rand(SIMS, 1, device=device)) # 1 / m\n",
    "\n",
    "    # Car Config\n",
    "    mass = 150 # kg\n",
    "    wheel_radius = 0.3 # m\n",
    "    with open('gearbox.txt', 'r') as file:\n",
    "        ratio_string = file.read()\n",
    "    gearbox_ratio = eval(ratio_string)\n",
    "\n",
    "    # Sim Config\n",
    "    x = torch.zeros(SIMS, 1, device=device, requires_grad=False)\n",
    "    x_dot = torch.zeros(SIMS, 1, device=device, requires_grad=False)\n",
    "    tau_effective = torch.zeros(SIMS, 1, device=device, requires_grad=False)\n",
    "    omega_belt = torch.zeros(SIMS, 1, device=device, requires_grad=False)\n",
    "    torque_max = torch.zeros(SIMS, 1, device=device, requires_grad=False)\n",
    "\n",
    "\n",
    "    dist = 30.48 # m\n",
    "\n",
    "    t = torch.ones(SIMS, 1, device=device, requires_grad=False) * -0.5\n",
    "\n",
    "    brakes = torch.ones(SIMS, 1, device=device, requires_grad=False)\n",
    "\n",
    "    i = 0\n",
    "    while i < ITERS and (x < dist).any():\n",
    "        brakes = t < 0.0\n",
    "\n",
    "        omega = torch.clamp(omega, min=2000/60*2*math.pi, max=3800/60*2*math.pi)\n",
    "\n",
    "        \n",
    "        if ~torch.isfinite(omega).any():\n",
    "            print(\"Omega is not finite\")\n",
    "            break\n",
    "\n",
    "        r_p = torch.clamp(r_p, min=0.01, max=0.24)\n",
    "        r_s = solveForOther(r_p, cToC, L)\n",
    "\n",
    "        if ~torch.isfinite(r_p).any():\n",
    "            print(\"r_p is not finite\")\n",
    "            break\n",
    "\n",
    "        if ~torch.isfinite(r_s).any():\n",
    "            print(\"r_s is not finite\")\n",
    "            break\n",
    "\n",
    "\n",
    "        tau = r_p / r_s\n",
    "        omega_belt = x_dot / (wheel_radius * gearbox_ratio * tau)\n",
    "        # tau_time[i] = [t[82, 0].cpu(), tau[82, 0].cpu()]\n",
    "\n",
    "        torque = tor_nddp(omega)\n",
    "        if ~torch.isfinite(torque).any():\n",
    "            print(\"Torque is not finite\")\n",
    "            break\n",
    "\n",
    "        prim = torch.clamp(omega * o_gain + r_p * rad_gain, min=1e-4)\n",
    "\n",
    "        sec = torch.clamp(r_s * rad_gain_s + torque / tau * torque_gain_s, min=1e-4)\n",
    "\n",
    "        natural_tension = (prim + sec) / math.tan(beta_naught)\n",
    "\n",
    "        # print(\"Natural Tension: {:.5f}\".format(natural_tension[0, 0]))\n",
    "        \n",
    "        inert = sigma * torch.pow(omega_belt, 2) * torch.pow(r_p, 2)\n",
    "\n",
    "        fr = torch.log((natural_tension - torque / (2 * r_p) - inert) / (natural_tension + torque / (2 * r_p) - inert))\n",
    "\n",
    "        fr = torch.isfinite(fr) * fr\n",
    "\n",
    "        theta_t = torch.asin((r_s - r_p) / cToC)\n",
    "        alpha_p = torch.pi - 2 * theta_t\n",
    "        alpha_s = torch.pi + 2 * theta_t\n",
    "\n",
    "        fr_bound = bauxite(alpha_p)\n",
    "        fr = torch.isfinite(fr) * fr\n",
    "        fr = torch.clamp(fr, min=-0.95*fr_bound, max=0.95*fr_bound)\n",
    "\n",
    "        wolframite_p = wolframite(torch.cat((fr, alpha_p), dim=1))\n",
    "        wolframite_s = wolframite(torch.cat((-fr, alpha_s), dim=1))\n",
    "\n",
    "        clamp_ratio = torch.log(prim / sec * wolframite_s / wolframite_p)\n",
    "\n",
    "        magnetite_p = magnetite(torch.cat((fr, tau, clamp_ratio), dim=1))\n",
    "\n",
    "        # print(clamp_ratio)\n",
    "        # print(magnetite_p)\n",
    "\n",
    "        F_naught = prim / magnetite_p[:, 2:3] + inert\n",
    "\n",
    "        torque_max = torch.abs(torch.exp(fr) - 1) * r_p * torch.clamp((F_naught - inert), min=0.0)\n",
    "\n",
    "        if ~torch.isfinite(fr).any():\n",
    "            print(\"fr is not finite\")\n",
    "            break\n",
    "\n",
    "        A_p = magnetite_p[:, 0:1]\n",
    "        tau_effective = magnetite_p[:, 1:2]\n",
    "        if ~torch.isfinite(A_p).any():\n",
    "            print(\"A_p is not finite\")\n",
    "            break\n",
    "\n",
    "        if ~torch.isfinite(tau_effective).any():\n",
    "            print(\"tau_effective is not finite\")\n",
    "            break\n",
    "        \n",
    "        if ~torch.isfinite(torque_max).any():\n",
    "            print(\"torque_max is not finite\")\n",
    "            break\n",
    "\n",
    "        if ~torch.isfinite(x).any():\n",
    "            print(\"x is not finite\")\n",
    "            break\n",
    "\n",
    "        if ~torch.isfinite(omega_belt).any():\n",
    "            print(\"omega_belt is not finite\")\n",
    "            break\n",
    "\n",
    "        deltaR_p = A_p * delta * omega_belt * r_p * sheave_terms * torch.isfinite(fr)\n",
    "        if ~torch.isfinite(deltaR_p).any():\n",
    "            print(\"deltaR_p is not finite\")\n",
    "            break\n",
    "        # deltaR_s = -deltaR_p * dLdRp(r_p, r_s, cToC) / dLdRs(r_p, r_s, cToC)\n",
    "\n",
    "        # Apply max torque to the car and remainder to the engine\n",
    "        omega_dot_engine = (torque - torque_max) / engine_inertia\n",
    "        omega_dot_car = torque_max / (mass * wheel_radius**2 * (gearbox_ratio**(-2)) * tau**2) * (brakes == 0)\n",
    "\n",
    "        \n",
    "        # If grip is sufficient match the rot speed of the two\n",
    "        omega_dot = torque / (engine_inertia + (mass * wheel_radius**2 * (gearbox_ratio**(-2)) * tau**2))\n",
    "        omega_dot_engine += (omega_dot - omega_dot_engine) * ((omega_dot_car > omega_dot_engine) & (brakes == 0))\n",
    "        omega_dot_car += (omega_dot - omega_dot_car) * ((omega_dot_car > omega_dot_engine) & (brakes == 0))\n",
    "\n",
    "\n",
    "        if ~torch.isfinite(omega_dot).any():\n",
    "            print(\"Omega dot is not finite\")\n",
    "            break\n",
    "\n",
    "        DELTA_T += (1e-5 - DELTA_T) * (torch.abs(x - dist) < 0.01)\n",
    "            \n",
    "        bitmap = x < dist\n",
    "\n",
    "        t += DELTA_T * bitmap\n",
    "        r_p += DELTA_T * deltaR_p * bitmap\n",
    "        # r_s += DELTA_T * deltaR_s\n",
    "        omega += DELTA_T * omega_dot_engine * bitmap\n",
    "        x += (x_dot * DELTA_T + 0.5 * omega_dot_car * DELTA_T**2 * gearbox_ratio * wheel_radius * tau_effective) * bitmap\n",
    "        x_dot += omega_dot_car * DELTA_T * gearbox_ratio * wheel_radius * tau_effective * bitmap\n",
    "\n",
    "        print(\"Iter: {:d} t[-1] {:.3f} x[-1] {:.5f} omega[-1] {:.5f} R_p[-1] {:.5f} R_s[-1] {:.5f} Natural Tension: {:.5f}\".format(i + 1, t[-1, 0], x[-1, 0], omega[-1, 0], r_p[-1, 0], r_s[-1, 0], natural_tension[-1, 0]), end=\"\\t\\t\\t\\r\")\n",
    "\n",
    "        i += 1\n",
    "\n",
    "# Clear out any NaNs\n",
    "t *= torch.isfinite(x)\n",
    "\n",
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# plt.figure()\n",
    "# plt.scatter(o_gain.cpu(), t.cpu())\n",
    "# plt.figure()\n",
    "# plt.scatter(tau_gain.cpu(), t.cpu())\n",
    "# plt.figure()\n",
    "# plt.scatter(tau_gain_s.cpu(), t.cpu())\n",
    "# plt.figure()\n",
    "# plt.scatter(torque_gain_s.cpu(), t.cpu())\n",
    "# plt.figure()\n",
    "# plt.title(\"Tau vs Time\")\n",
    "# plt.scatter(tau_time[:, 0], tau_time[:, 1])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.6 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "91eeeaf35c12a4cfd84772b7b4ca866a6da7c05b16a8b6001c69ad6e4da5e757"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
